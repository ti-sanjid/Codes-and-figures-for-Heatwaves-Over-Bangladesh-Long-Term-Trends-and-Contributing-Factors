{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "0a-Zu118LJ5o"
   },
   "source": [
    "# Imports and installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.feature as cf\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "\n",
    "from cartopy.util import add_cyclic_point\n",
    "from matplotlib import animation\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime,timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime,timedelta\n",
    "import warnings\n",
    "import math\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "id": "9SxMMVBF5wuu"
   },
   "source": [
    "# Processing data for the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "Tuj-avjYYLM5"
   },
   "source": [
    "## Daily maximums\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "eDLy6UQkfLPs"
   },
   "source": [
    "Here we are using ERA5 data to calculate our **daily maximum t2m**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This is a very time consuming process.\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "directory_path='/content/drive/MyDrive/AP_HW/ERA5 Data/t2m_d2m_sp'\n",
    "\n",
    "t2m_list=[]\n",
    "for filename in tqdm(sorted(os.listdir(directory_path))):\n",
    "  if filename.endswith('.nc'):\n",
    "    filepath=os.path.join(directory_path,filename)\n",
    "    ds=xr.open_dataset(filepath)\n",
    "    year=int(filename[11:-3])\n",
    "    lat_range=slice(26.5,20.75)\n",
    "    lon_range=slice(88,92.5)\n",
    "    ds_t2m=ds.t2m.sel(latitude=lat_range,longitude=lon_range)\n",
    "    ds_t2m_bdt=ds_t2m.shift(time=6)\n",
    "    ds_t2m_C=ds_t2m_bdt-273.15\n",
    "    ds_t2m_C=ds_t2m_C.assign_attrs(ds_t2m.attrs)\n",
    "    ds_t2m_C.attrs['units']= '° C'\n",
    "    tmax_ds_daily=ds_t2m_C.resample(time='D').max()\n",
    "    t2m_list.append(tmax_ds_daily)\n",
    "max_t2m_no_mask=xr.concat(t2m_list,dim='time')\n",
    "max_t2m_no_mask.to_netcdf('/content/drive/MyDrive/AP_HW/Scripts-ll/HW_dates/data/max_t2m_no_mask.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "P0vy2yRWfBQr"
   },
   "source": [
    "Here we are using Ept data calculated using the `EPT calculation.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=xr.open_mfdataset('/content/drive/MyDrive/AP_HW/ERA5 Data/EPT/*.nc')\n",
    "lat_range=slice(26.5,20.75)\n",
    "lon_range=slice(88,92.5)\n",
    "ds_ept=ds.ept.sel(latitude=lat_range,longitude=lon_range)\n",
    "ds_ept_bdt=ds_ept.shift(time=6)\n",
    "ds_ept_bdt\n",
    "ds_ept_bdt.to_netcdf('/content/drive/MyDrive/AP_HW/Scripts-ll/HW_dates/data/max_ept_no_mask.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "id": "V4VyOI92e4b7"
   },
   "source": [
    "Here we are using WBT data calculated using the `WBT calculation.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbts=xr.open_mfdataset('/content/drive/MyDrive/AP_HW/Scripts-ll/WBT/wbt_files/*.nc')\n",
    "lat_range=slice(26.5,20.75)\n",
    "lon_range=slice(88,92.5)\n",
    "wbt_ds=wbts.wbt.sel(latitude=lat_range,longitude=lon_range)\n",
    "wbt_ds.to_netcdf('/content/drive/MyDrive/AP_HW/Scripts-ll/HW_dates/data/max_wbt_no_mask.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the saved files for t2m, ept, wbt.\n",
    "\n",
    "ds_ept =xr.open_dataset('/content/drive/MyDrive/AP_HW/Scripts-ll/HW_dates/data/max_ept_no_mask.nc')\n",
    "ds_t2m =xr.open_dataset('/content/drive/MyDrive/AP_HW/Scripts-ll/HW_dates/data/max_t2m_no_mask.nc')\n",
    "ds_wbt =xr.open_dataset('/content/drive/MyDrive/AP_HW/Scripts-ll/HW_dates/data/max_wbt_no_mask.nc')\n",
    "ds_wbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting from K to C\n",
    "\n",
    "ds_ept_degC=ds_ept-273.15\n",
    "ds_t2m_degC=ds_t2m.copy()\n",
    "ds_wbt_degC=ds_wbt-273.15\n",
    "ds_wbt_degC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making daily data\n",
    "\n",
    "ds_ept_daily_max=ds_ept_degC.ept.resample(time='D').max()\n",
    "ds_t2m_daily_max=ds_t2m_degC.t2m.resample(time='D').max()\n",
    "ds_wbt_daily_max=ds_wbt_degC.wbt.resample(time='D').max()\n",
    "ds_wbt_daily_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking Spatial Average for BD\n",
    "\n",
    "weights=np.cos(np.deg2rad(ds_ept_daily_max.latitude))\n",
    "weights.name='weights'\n",
    "daily_ept_weighted = ds_ept_daily_max.weighted(weights)\n",
    "BD_mean_max_ept = daily_ept_weighted.mean(['longitude','latitude'])\n",
    "BD_mean_max_ept\n",
    "\n",
    "weights=np.cos(np.deg2rad(ds_t2m_daily_max.latitude))\n",
    "weights.name='weights'\n",
    "daily_t2m_weighted = ds_t2m_daily_max.weighted(weights)\n",
    "BD_mean_max_t2m = daily_t2m_weighted.mean(['longitude','latitude'])\n",
    "BD_mean_max_t2m\n",
    "\n",
    "weights=np.cos(np.deg2rad(ds_wbt_daily_max.latitude))\n",
    "weights.name='weights'\n",
    "daily_wbt_weighted = ds_wbt_daily_max.weighted(weights)\n",
    "BD_mean_max_wbt = daily_wbt_weighted.mean(['longitude','latitude'])\n",
    "BD_mean_max_wbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking data for premonsoon and monsoon\n",
    "\n",
    "BD_mean_max_ept=BD_mean_max_ept.sel(time=BD_mean_max_ept.time.dt.month.isin([3,4,5,6,7,8,9]))\n",
    "BD_mean_max_t2m=BD_mean_max_t2m.sel(time=BD_mean_max_t2m.time.dt.month.isin([3,4,5,6,7,8,9]))\n",
    "BD_mean_max_wbt=BD_mean_max_wbt.sel(time=BD_mean_max_wbt.time.dt.month.isin([3,4,5,6,7,8,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_t2m_daily_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to Dataframe\n",
    "max_ept_df=BD_mean_max_ept.to_dataframe().reset_index()\n",
    "max_t2m_df=BD_mean_max_t2m.to_dataframe().reset_index()\n",
    "max_wbt_df=BD_mean_max_wbt.to_dataframe().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_wbt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the dataframes for t2m,ept,wbt.\n",
    "df = pd.merge(max_ept_df,max_t2m_df)\n",
    "df=pd.merge(df,max_wbt_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the file to use it later for plotting.\n",
    "df.to_csv('/content/drive/MyDrive/AP_HW/Scripts-ll/Trends/data/ept_t2m_wbt_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "RT75FFHBdKAS"
   },
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the file for plotting\n",
    "df=pd.read_csv('/content/drive/MyDrive/AP_HW/Scripts-ll/Trends/data/ept_t2m_wbt_df.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the dataframe and separating it by season\n",
    "clean_df=df.dropna()\n",
    "clean_df['time']=pd.to_datetime(clean_df['time'])\n",
    "df_mam = clean_df[(clean_df['time'].dt.month >= 3) & (clean_df['time'].dt.month <= 5)]\n",
    "df_jjas = clean_df[(clean_df['time'].dt.month >= 6) & (clean_df['time'].dt.month <= 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mam['ept'].describe(percentiles=[0.95])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mam['t2m'].describe(percentiles=[0.95])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mam['wbt'].describe(percentiles=[0.95])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions used for plotting.\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Generate a common x-axis range based on two temperature arrays\n",
    "def x_vals_range(temp_values_1,temp_values_2):\n",
    "  value_floor_1 = np.floor(temp_values_1.min())\n",
    "  value_ceil_1 = np.ceil(temp_values_1.max())\n",
    "  value_floor_2 = np.floor(temp_values_2.min())\n",
    "  value_ceil_2 = np.ceil(temp_values_2.max())\n",
    "  value_floor=min(value_floor_1,value_floor_2)\n",
    "  value_ceil= max(value_ceil_1,value_ceil_2)\n",
    "  x_vals=np.arange(value_floor, value_ceil + 0.01, 0.1)\n",
    "  return x_vals\n",
    "\n",
    "# Compute Gaussian KDEs for two datasets and return evaluated values\n",
    "def calculate_kde(temp_values_1,temp_values_2):\n",
    "  kde_1 = gaussian_kde(temp_values_1)  # KDE for the first dataset\n",
    "  kde_2 = gaussian_kde(temp_values_2)  # KDE for the second dataset\n",
    "  x_vals= x_vals_range(temp_values_1,temp_values_2)\n",
    "  # Evaluate KDE\n",
    "  y_kde_1 = kde_1(x_vals)\n",
    "  y_kde_2 = kde_2(x_vals)\n",
    "  return y_kde_1,y_kde_2,x_vals\n",
    "\n",
    "# Calculate 25th, 50th, and 75th percentiles of a dataset\n",
    "def calculate_quartiles(data):\n",
    "    return np.percentile(data, [25, 50, 75])\n",
    "\n",
    "# Compute the percentage increase from value1 to value2\n",
    "def percentage_increase(value1,value2):\n",
    "  difference=value2-value1\n",
    "  percentage=(difference/value1)*100\n",
    "  return percentage\n",
    "\n",
    "# Calculate percentage increase in area under KDE curves for a specific region\n",
    "def increase_in_filled_region(y_kde_1,y_kde_2,x_vals,condition):\n",
    "  area_1=np.trapz(y_kde_1[condition], x_vals[condition])\n",
    "  area_2=np.trapz(y_kde_2[condition], x_vals[condition])\n",
    "  percentage=((area_2-area_1)/area_1)*100\n",
    "  return percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Table_1\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First row: MAM data\n",
    "df_1=df_mam[(df_mam['time'].dt.year >= 1971) & (df_mam['time'].dt.year <= 1985)]\n",
    "df_2=df_mam[(df_mam['time'].dt.year >= 2010) & (df_mam['time'].dt.year <= 2024)]\n",
    "\n",
    "# Evaluate KDE\n",
    "t2m_mam_y_kde_1,t2m_mam_y_kde_2,t2m_x_vals = calculate_kde(df_1.t2m,df_2.t2m)\n",
    "ept_mam_y_kde_1,ept_mam_y_kde_2,ept_x_vals = calculate_kde(df_1.ept,df_2.ept)\n",
    "wbt_mam_y_kde_1,wbt_mam_y_kde_2,wbt_x_vals = calculate_kde(df_1.wbt,df_2.wbt)\n",
    "\n",
    "# quartiles\n",
    "t2m_mam_quartiles_1 = calculate_quartiles(df_1.t2m)\n",
    "t2m_mam_quartiles_2 = calculate_quartiles(df_2.t2m)\n",
    "ept_mam_quartiles_1 = calculate_quartiles(df_1.ept)\n",
    "ept_mam_quartiles_2 = calculate_quartiles(df_2.ept)\n",
    "wbt_mam_quartiles_1 = calculate_quartiles(df_1.wbt)\n",
    "wbt_mam_quartiles_2 = calculate_quartiles(df_2.wbt)\n",
    "increase_mam_t2m=percentage_increase(t2m_mam_quartiles_1,t2m_mam_quartiles_2)\n",
    "increase_mam_ept=percentage_increase(ept_mam_quartiles_1,ept_mam_quartiles_2)\n",
    "increase_mam_wbt=percentage_increase(wbt_mam_quartiles_1,wbt_mam_quartiles_2)\n",
    "\n",
    "\n",
    "\n",
    "print(f'T2M Percentile premonsoon (1971-1985):',f'25th:{t2m_mam_quartiles_1[0]:.2f}, 50th:{t2m_mam_quartiles_1[1]:.2f}, 75th:{t2m_mam_quartiles_1[2]:.2f}')\n",
    "print(f'T2M Percentile premonsoon (2009-2024):',f'25th:{t2m_mam_quartiles_2[0]:.2f}, 50th:{t2m_mam_quartiles_2[1]:.2f}, 75th:{t2m_mam_quartiles_2[2]:.2f}')\n",
    "print(f'T2M Percentile premonsoon Increase   :',f'25th:+{increase_mam_t2m[0]:.2f}%, 50th:+{increase_mam_t2m[1]:.2f}%, 75th:+{increase_mam_t2m[2]:.2f}%')\n",
    "\n",
    "print(f'EPT Percentile premonsoon (1971-1985):',f'25th:{ept_mam_quartiles_1[0]:.2f}, 50th:{ept_mam_quartiles_1[1]:.2f}, 75th:{ept_mam_quartiles_1[2]:.2f}')\n",
    "print(f'EPT Percentile premonsoon (2009-2024):',f'25th:{ept_mam_quartiles_2[0]:.2f}, 50th:{ept_mam_quartiles_2[1]:.2f}, 75th:{ept_mam_quartiles_2[2]:.2f}')\n",
    "print(f'EPT Percentile premonsoon Increase   :',f'25th:+{increase_mam_ept[0]:.2f}%, 50th:+{increase_mam_ept[1]:.2f}%, 75th:+{increase_mam_ept[2]:.2f}%')\n",
    "\n",
    "print(f'WBT Percentile premonsoon (1971-1985):',f'25th:{wbt_mam_quartiles_1[0]:.2f}, 50th:{wbt_mam_quartiles_1[1]:.2f}, 75th:{wbt_mam_quartiles_1[2]:.2f}')\n",
    "print(f'WBT Percentile premonsoon (2009-2024):',f'25th:{wbt_mam_quartiles_2[0]:.2f}, 50th:{wbt_mam_quartiles_2[1]:.2f}, 75th:{wbt_mam_quartiles_2[2]:.2f}')\n",
    "print(f'WBT Percentile premonsoon Increase   :',f'25th:+{increase_mam_wbt[0]:.2f}%, 50th:+{increase_mam_wbt[1]:.2f}%, 75th:+{increase_mam_wbt[2]:.2f}%')\n",
    "\n",
    "# Second row: JJAS data\n",
    "df_1=df_jjas[(df_jjas['time'].dt.year >= 1971) & (df_jjas['time'].dt.year <= 1985)]\n",
    "df_2=df_jjas[(df_jjas['time'].dt.year >= 2010) & (df_jjas['time'].dt.year <= 2024)]\n",
    "\n",
    "# Evaluate KDE\n",
    "t2m_jjas_y_kde_1,t2m_jjas_y_kde_2,t2m_x_vals = calculate_kde(df_1.t2m,df_2.t2m)\n",
    "ept_jjas_y_kde_1,ept_jjas_y_kde_2,ept_x_vals = calculate_kde(df_1.ept,df_2.ept)\n",
    "wbt_jjas_y_kde_1,wbt_jjas_y_kde_2,wbt_x_vals = calculate_kde(df_1.wbt,df_2.wbt)\n",
    "\n",
    "# quartiles\n",
    "t2m_jjas_quartiles_1 = calculate_quartiles(df_1.t2m)\n",
    "t2m_jjas_quartiles_2 = calculate_quartiles(df_2.t2m)\n",
    "ept_jjas_quartiles_1 = calculate_quartiles(df_1.ept)\n",
    "ept_jjas_quartiles_2 = calculate_quartiles(df_2.ept)\n",
    "wbt_jjas_quartiles_1 = calculate_quartiles(df_1.wbt)\n",
    "wbt_jjas_quartiles_2 = calculate_quartiles(df_2.wbt)\n",
    "increase_jjas_t2m=percentage_increase(t2m_jjas_quartiles_1,t2m_jjas_quartiles_2)\n",
    "increase_jjas_ept=percentage_increase(ept_jjas_quartiles_1,ept_jjas_quartiles_2)\n",
    "increase_jjas_wbt=percentage_increase(wbt_jjas_quartiles_1,wbt_jjas_quartiles_2)\n",
    "\n",
    "\n",
    "print(f'T2M Percentile monsoon (1971-1985):',f'25th:{t2m_jjas_quartiles_1[0]:.2f}, 50th:{t2m_jjas_quartiles_1[1]:.2f}, 75th:{t2m_jjas_quartiles_1[2]:.2f}')\n",
    "print(f'T2M Percentile monsoon (2009-2024):',f'25th:{t2m_jjas_quartiles_2[0]:.2f}, 50th:{t2m_jjas_quartiles_2[1]:.2f}, 75th:{t2m_jjas_quartiles_2[2]:.2f}')\n",
    "print(f'T2M Percentile monsoon Increase   :',f'25th:+{increase_jjas_t2m[0]:.2f}%, 50th:+{increase_jjas_t2m[1]:.2f}%, 75th:+{increase_jjas_t2m[2]:.2f}%')\n",
    "\n",
    "print(f'EPT Percentile monsoon (1971-1985):',f'25th:{ept_jjas_quartiles_1[0]:.2f}, 50th:{ept_jjas_quartiles_1[1]:.2f}, 75th:{ept_jjas_quartiles_1[2]:.2f}')\n",
    "print(f'EPT Percentile monsoon (2009-2024):',f'25th:{ept_jjas_quartiles_2[0]:.2f}, 50th:{ept_jjas_quartiles_2[1]:.2f}, 75th:{ept_jjas_quartiles_2[2]:.2f}')\n",
    "print(f'EPT Percentile monsoon Increase   :',f'25th:+{increase_jjas_ept[0]:.2f}%, 50th:+{increase_jjas_ept[1]:.2f}%, 75th:+{increase_jjas_ept[2]:.2f}%')\n",
    "\n",
    "print(f'WBT Percentile monsoon (1971-1985):',f'25th:{wbt_jjas_quartiles_1[0]:.2f}, 50th:{wbt_jjas_quartiles_1[1]:.2f}, 75th:{wbt_jjas_quartiles_1[2]:.2f}')\n",
    "print(f'WBT Percentile monsoon (2009-2024):',f'25th:{wbt_jjas_quartiles_2[0]:.2f}, 50th:{wbt_jjas_quartiles_2[1]:.2f}, 75th:{wbt_jjas_quartiles_2[2]:.2f}')\n",
    "print(f'WBT Percentile monsoon Increase   :',f'25th:+{increase_jjas_wbt[0]:.2f}%, 50th:+{increase_jjas_wbt[1]:.2f}%, 75th:+{increase_jjas_wbt[2]:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Build data manually using your calculated quartiles & percentage increases\n",
    "\n",
    "table_data = {\n",
    "    \"Season\": [\"Pre-monsoon\"]*3 + [\"Monsoon\"]*3,\n",
    "    \"Quartiles\": [\"Q1\", \"Q2\", \"Q3\", \"Q1\", \"Q2\", \"Q3\"],\n",
    "\n",
    "    \"T2M (1971–1985)\": [t2m_mam_quartiles_1[0], t2m_mam_quartiles_1[1], t2m_mam_quartiles_1[2],\n",
    "                        t2m_jjas_quartiles_1[0], t2m_jjas_quartiles_1[1], t2m_jjas_quartiles_1[2]],\n",
    "    \"T2M (2009–2024)\": [t2m_mam_quartiles_2[0], t2m_mam_quartiles_2[1], t2m_mam_quartiles_2[2],\n",
    "                        t2m_jjas_quartiles_2[0], t2m_jjas_quartiles_2[1], t2m_jjas_quartiles_2[2]],\n",
    "    \"T2M Increase (%)\": [increase_mam_t2m[0], increase_mam_t2m[1], increase_mam_t2m[2],\n",
    "                         increase_jjas_t2m[0], increase_jjas_t2m[1], increase_jjas_t2m[2]],\n",
    "\n",
    "    \"EPT (1971–1985)\": [ept_mam_quartiles_1[0], ept_mam_quartiles_1[1], ept_mam_quartiles_1[2],\n",
    "                        ept_jjas_quartiles_1[0], ept_jjas_quartiles_1[1], ept_jjas_quartiles_1[2]],\n",
    "    \"EPT (2009–2024)\": [ept_mam_quartiles_2[0], ept_mam_quartiles_2[1], ept_mam_quartiles_2[2],\n",
    "                        ept_jjas_quartiles_2[0], ept_jjas_quartiles_2[1], ept_jjas_quartiles_2[2]],\n",
    "    \"EPT Increase (%)\": [increase_mam_ept[0], increase_mam_ept[1], increase_mam_ept[2],\n",
    "                         increase_jjas_ept[0], increase_jjas_ept[1], increase_jjas_ept[2]],\n",
    "\n",
    "    \"WBT (1971–1985)\": [wbt_mam_quartiles_1[0], wbt_mam_quartiles_1[1], wbt_mam_quartiles_1[2],\n",
    "                        wbt_jjas_quartiles_1[0], wbt_jjas_quartiles_1[1], wbt_jjas_quartiles_1[2]],\n",
    "    \"WBT (2009–2024)\": [wbt_mam_quartiles_2[0], wbt_mam_quartiles_2[1], wbt_mam_quartiles_2[2],\n",
    "                        wbt_jjas_quartiles_2[0], wbt_jjas_quartiles_2[1], wbt_jjas_quartiles_2[2]],\n",
    "    \"WBT Increase (%)\": [increase_mam_wbt[0], increase_mam_wbt[1], increase_mam_wbt[2],\n",
    "                         increase_jjas_wbt[0], increase_jjas_wbt[1], increase_jjas_wbt[2]]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_table = pd.DataFrame(table_data)\n",
    "\n",
    "# Round values\n",
    "df_table = df_table.round(2)\n",
    "\n",
    "# Display in notebook\n",
    "import IPython.display as disp\n",
    "disp.display(df_table)\n",
    "\n",
    "# Export if needed\n",
    "df_table.to_csv(\"/content/drive/MyDrive/AP_HW/Scripts-ll/Manuscript codes/Fig_3/Fig_3_data/Table_1.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "id": "QkO4YPJ0ggEU"
   },
   "source": [
    "we used the no mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title figure\n",
    "\n",
    "# Now we are  plotting the PDFs  for the data above.\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(15, 12))\n",
    "axs=axs.flatten()\n",
    "\n",
    "# First row: MAM data\n",
    "df_1=df_mam[(df_mam['time'].dt.year >= 1971) & (df_mam['time'].dt.year <= 1985)]\n",
    "df_2=df_mam[(df_mam['time'].dt.year >= 2010) & (df_mam['time'].dt.year <= 2024)]\n",
    "\n",
    "# Evaluate KDE\n",
    "t2m_mam_y_kde_1,t2m_mam_y_kde_2,t2m_x_vals = calculate_kde(df_1.t2m,df_2.t2m)\n",
    "ept_mam_y_kde_1,ept_mam_y_kde_2,ept_x_vals = calculate_kde(df_1.ept,df_2.ept)\n",
    "wbt_mam_y_kde_1,wbt_mam_y_kde_2,wbt_x_vals = calculate_kde(df_1.wbt,df_2.wbt)\n",
    "\n",
    "\n",
    "# Plot using Matplotlib\n",
    "axs[0].plot(t2m_x_vals, t2m_mam_y_kde_1,label=f't2m (1971-1985)',color='blue', linestyle='--')\n",
    "axs[0].plot(t2m_x_vals, t2m_mam_y_kde_2, label='t2m (2010-2024)', color='red')\n",
    "axs[0].fill_between(t2m_x_vals, t2m_mam_y_kde_2, where=(t2m_x_vals > np.nanpercentile(df_mam.t2m, 95)), color='red', alpha=0.5)\n",
    "axs[0].fill_between(t2m_x_vals, t2m_mam_y_kde_1, where=(t2m_x_vals > np.nanpercentile(df_mam.t2m, 95)), color='blue', alpha=0.8)\n",
    "\n",
    "\n",
    "axs[2].plot(ept_x_vals, ept_mam_y_kde_1, label='ept (1971-1985)', color='blue', linestyle='--')\n",
    "axs[2].plot(ept_x_vals, ept_mam_y_kde_2, label='ept (2010-2024)', color='red')\n",
    "axs[2].fill_between(ept_x_vals, ept_mam_y_kde_2, where=(ept_x_vals > np.nanpercentile(df_mam.ept, 95)), color='red', alpha=0.5)\n",
    "axs[2].fill_between(ept_x_vals, ept_mam_y_kde_1, where=(ept_x_vals > np.nanpercentile(df_mam.ept, 95)), color='blue', alpha=0.8)\n",
    "\n",
    "axs[4].plot(wbt_x_vals, wbt_mam_y_kde_1, label='wbt (1971-1985)', color='blue', linestyle='--')\n",
    "axs[4].plot(wbt_x_vals, wbt_mam_y_kde_2, label='wbt (2010-2024)', color='red')\n",
    "axs[4].fill_between(wbt_x_vals, wbt_mam_y_kde_2, where=(wbt_x_vals > np.nanpercentile(df_mam.wbt, 95)), color='red', alpha=0.5)\n",
    "axs[4].fill_between(wbt_x_vals, wbt_mam_y_kde_1, where=(wbt_x_vals > np.nanpercentile(df_mam.wbt, 95)), color='blue', alpha=0.8)\n",
    "\n",
    "increased_area=increase_in_filled_region(t2m_mam_y_kde_1,t2m_mam_y_kde_2,t2m_x_vals,t2m_x_vals > np.nanpercentile(df_mam.t2m, 95))\n",
    "axs[0].annotate(f'+{increased_area:.2f}%', xy=(38, 0.014),fontsize=9, color='red',)\n",
    "\n",
    "increased_area=increase_in_filled_region(ept_mam_y_kde_1,ept_mam_y_kde_2,ept_x_vals,ept_x_vals > np.nanpercentile(df_mam.ept, 95))\n",
    "axs[2].annotate(f'+{increased_area:.2f}%', xy=(110, 0.0078),fontsize=9, color='red',)\n",
    "\n",
    "increased_area=increase_in_filled_region(wbt_mam_y_kde_1,wbt_mam_y_kde_2,wbt_x_vals,wbt_x_vals > np.nanpercentile(df_mam.wbt, 95))\n",
    "axs[4].annotate(f'+{increased_area:.2f}%', xy=(30.2, 0.062),fontsize=9, color='red',)\n",
    "\n",
    "axs[0].arrow(x=36, y=0.016, dx=1.5, dy=0, width=.002,color='red',head_width=0.008,head_length=0.4,overhang=0.1)\n",
    "axs[2].arrow(x=104.3, y=0.0085, dx=4.3, dy=0, width=.0003,color='red',head_width=0.0018,head_length=1.1,overhang=0.1)\n",
    "axs[4].arrow(x=28.25, y=0.065, dx=1.5, dy=0, width=.002,color='red',head_width=0.008,head_length=0.4,overhang=0.1)\n",
    "\n",
    "\n",
    "# # Set x-ticks\n",
    "axs[0].set_xticks(np.arange(20, 45+1, 5))\n",
    "axs[2].set_xticks(np.arange(35, 125+1, 15))\n",
    "axs[4].set_xticks(np.arange(15, 35+1, 5))\n",
    "axs[2].set_xlim(32, 135)\n",
    "axs[4].set_xlim(11, 35)\n",
    "\n",
    "\n",
    "# # Set y-ticks\n",
    "axs[0].set_yticks(np.arange(0, 0.25 + 0.01, 0.05))\n",
    "axs[2].set_yticks(np.arange(0, 0.045 + 0.001, 0.01))\n",
    "axs[4].set_yticks(np.arange(0, 0.25 + 0.01, 0.05))\n",
    "axs[0].set_ylim(0, 0.25)\n",
    "axs[2].set_ylim(0, 0.045)\n",
    "axs[4].set_ylim(0, 0.25)\n",
    "\n",
    "\n",
    "\n",
    "# Labels and titles\n",
    "axs[0].set_xlabel('2m Temperature(°C)')\n",
    "axs[0].set_ylabel('probability of occurrence')\n",
    "axs[0].set_title('Pre-monsoon',fontsize=10)\n",
    "\n",
    "axs[2].set_xlabel('Equivalent Potential Temperature(°C)')\n",
    "axs[2].set_ylabel('probability of occurrence')\n",
    "axs[2].set_title('Pre-monsoon',fontsize=10)\n",
    "\n",
    "axs[4].set_xlabel('Wet Bulb Temperature(°C)')\n",
    "axs[4].set_ylabel('probability of occurrence')\n",
    "axs[4].set_title('Pre-monsoon',fontsize=10)\n",
    "\n",
    "# Add legends\n",
    "axs[0].legend(loc='right',bbox_to_anchor=(1, 0.92),ncol=2)\n",
    "axs[2].legend(loc='right',bbox_to_anchor=(1, 0.92),ncol=2)\n",
    "axs[4].legend(loc='right',bbox_to_anchor=(1, 0.92),ncol=2)\n",
    "\n",
    "\n",
    "# Second row: JJAS data\n",
    "df_1=df_jjas[(df_jjas['time'].dt.year >= 1971) & (df_jjas['time'].dt.year <= 1985)]\n",
    "df_2=df_jjas[(df_jjas['time'].dt.year >= 2010) & (df_jjas['time'].dt.year <= 2024)]\n",
    "\n",
    "# Evaluate KDE\n",
    "t2m_jjas_y_kde_1,t2m_jjas_y_kde_2,t2m_x_vals = calculate_kde(df_1.t2m,df_2.t2m)\n",
    "ept_jjas_y_kde_1,ept_jjas_y_kde_2,ept_x_vals = calculate_kde(df_1.ept,df_2.ept)\n",
    "wbt_jjas_y_kde_1,wbt_jjas_y_kde_2,wbt_x_vals = calculate_kde(df_1.wbt,df_2.wbt)\n",
    "\n",
    "\n",
    "# quartiles\n",
    "t2m_jjas_quartiles_1 = calculate_quartiles(df_1.t2m)\n",
    "t2m_jjas_quartiles_2 = calculate_quartiles(df_2.t2m)\n",
    "ept_jjas_quartiles_1 = calculate_quartiles(df_1.ept)\n",
    "ept_jjas_quartiles_2 = calculate_quartiles(df_2.ept)\n",
    "wbt_jjas_quartiles_1 = calculate_quartiles(df_1.wbt)\n",
    "wbt_jjas_quartiles_2 = calculate_quartiles(df_2.wbt)\n",
    "\n",
    "# Plot using Matplotlib\n",
    "axs[1].plot(t2m_x_vals, t2m_jjas_y_kde_1, label=f't2m (1971-1985) ', color='blue', linestyle='--')\n",
    "axs[1].plot(t2m_x_vals, t2m_jjas_y_kde_2, label='t2m (2010-2024)', color='red')\n",
    "axs[1].fill_between(t2m_x_vals, t2m_jjas_y_kde_2, where=(t2m_x_vals > np.nanpercentile(df_jjas.t2m, 95)), color='red', alpha=0.5)\n",
    "axs[1].fill_between(t2m_x_vals, t2m_jjas_y_kde_1, where=(t2m_x_vals > np.nanpercentile(df_jjas.t2m, 95)), color='blue', alpha=0.8)\n",
    "\n",
    "\n",
    "axs[3].plot(ept_x_vals, ept_jjas_y_kde_1, label='ept (1971-1985)', color='blue', linestyle='--')\n",
    "axs[3].plot(ept_x_vals, ept_jjas_y_kde_2, label='ept (2010-2024)', color='red')\n",
    "axs[3].fill_between(ept_x_vals, ept_jjas_y_kde_2, where=(ept_x_vals > np.nanpercentile(df_jjas.ept, 95)), color='red', alpha=0.5)\n",
    "axs[3].fill_between(ept_x_vals, ept_jjas_y_kde_1, where=(ept_x_vals > np.nanpercentile(df_jjas.ept, 95)), color='blue', alpha=0.8)\n",
    "\n",
    "axs[5].plot(wbt_x_vals, wbt_jjas_y_kde_1, label='wbt (1971-1985)', color='blue', linestyle='--')\n",
    "axs[5].plot(wbt_x_vals, wbt_jjas_y_kde_2, label='wbt (2010-2024)', color='red')\n",
    "axs[5].fill_between(wbt_x_vals, wbt_jjas_y_kde_2, where=(wbt_x_vals > np.nanpercentile(df_jjas.wbt, 95)), color='red', alpha=0.5)\n",
    "axs[5].fill_between(wbt_x_vals, wbt_jjas_y_kde_1, where=(wbt_x_vals > np.nanpercentile(df_jjas.wbt, 95)), color='blue', alpha=0.8)\n",
    "\n",
    "increased_area=increase_in_filled_region(t2m_jjas_y_kde_1,t2m_jjas_y_kde_2,t2m_x_vals,t2m_x_vals > np.nanpercentile(df_jjas.t2m, 95))\n",
    "axs[1].annotate(f'+{increased_area:.2f}%', xy=(35.4, 0.046),fontsize=9, color='red',)\n",
    "\n",
    "increased_area=increase_in_filled_region(ept_jjas_y_kde_1,ept_jjas_y_kde_2,ept_x_vals,ept_x_vals > np.nanpercentile(df_jjas.ept, 95))\n",
    "axs[3].annotate(f'+{increased_area:.2f}%', xy=(108.85, 0.02),fontsize=9, color='red',)\n",
    "\n",
    "increased_area=increase_in_filled_region(wbt_jjas_y_kde_1,wbt_jjas_y_kde_2,wbt_x_vals,wbt_x_vals > np.nanpercentile(df_jjas.wbt, 95))\n",
    "axs[5].annotate(f'+{increased_area:.2f}%', xy=(29.2, 0.1),fontsize=9, color='red',)\n",
    "\n",
    "axs[1].arrow(x=33.6, y=0.05, dx=1.3, dy=0, width=.0035,color='red',head_width=0.0125,head_length=0.4,overhang=0.1)\n",
    "axs[3].arrow(x=104.8, y=0.0215, dx=3, dy=0, width=.0012,color='red',head_width=0.0055,head_length=0.9,overhang=0.1)\n",
    "axs[5].arrow(x=28.4, y=0.115, dx=0.6, dy=0, width=.008,color='red',head_width=0.035,head_length=0.15,overhang=0.1)\n",
    "\n",
    "\n",
    "\n",
    "# # Set x-ticks\n",
    "axs[1].set_xticks(np.arange(20, 42+1, 5))\n",
    "axs[3].set_xticks(np.arange(75, 130+1, 10))\n",
    "axs[5].set_xticks(np.arange(22, 32+1, 2))\n",
    "axs[1].set_xlim(20, 42)\n",
    "\n",
    "\n",
    "# # Set y-ticks\n",
    "axs[1].set_yticks(np.arange(0, 0.45 + 0.01, 0.05))\n",
    "axs[3].set_yticks(np.arange(0, 0.18 + 0.01, 0.03))\n",
    "axs[5].set_yticks(np.arange(0, 1 + 0.01, 0.1))\n",
    "axs[1].set_ylim(0, 0.45)\n",
    "axs[3].set_ylim(0, 0.17)\n",
    "axs[5].set_ylim(0, 1)\n",
    "\n",
    "\n",
    "# Labels and titles\n",
    "axs[1].set_xlabel('2m Temperature(°C)')\n",
    "axs[1].set_ylabel('probability of occurrence')\n",
    "axs[1].set_title('Monsoon',fontsize=10)\n",
    "\n",
    "axs[3].set_xlabel('Equivalent Potential Temperature(°C)')\n",
    "axs[3].set_ylabel('probability of occurrence')\n",
    "axs[3].set_title('Monsoon',fontsize=10)\n",
    "\n",
    "axs[5].set_xlabel('Wet Bulb Temperature(°C)')\n",
    "axs[5].set_ylabel('probability of occurrence')\n",
    "axs[5].set_title('Monsoon',fontsize=10)\n",
    "\n",
    "# Add legends\n",
    "axs[1].legend(loc='right',bbox_to_anchor=(1, 0.92),ncol=2)\n",
    "axs[3].legend(loc='right',bbox_to_anchor=(1, 0.92),ncol=2)\n",
    "axs[5].legend(loc='right',bbox_to_anchor=(1, 0.92),ncol=2)\n",
    "\n",
    "plt.subplots_adjust( wspace=0.2,hspace=0.28,top=0.9)\n",
    "plt.suptitle('Probability Density Functions',y=0.94,fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(\"/content/drive/MyDrive/AP_HW/Scripts-ll/Manuscript codes/All_Figures/Fig_3_probability_density_functions.jpg\",\n",
    "            dpi=300, format=\"jpg\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
