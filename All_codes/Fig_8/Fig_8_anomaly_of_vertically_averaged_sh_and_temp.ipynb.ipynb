{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a-Zu118LJ5o"
   },
   "source": [
    "# Imports and installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime,timedelta\n",
    "import warnings\n",
    "import math\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cartopy.feature as cf\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.mpl.ticker as cticker\n",
    "\n",
    "from cartopy.util import add_cyclic_point\n",
    "from matplotlib import animation\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "from matplotlib.cm import get_cmap\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7rKqp--CmKXq"
   },
   "source": [
    "# Temperature Anomaly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtwJiRz0ZMFM"
   },
   "source": [
    "\n",
    "*   We calculated the **temperature anomalies** for each event using the dates from `HW_list_rolling_def.csv` for **pre-monsoon (MAM)** and **monsoon (JJAS)** seasons.  \n",
    "*   The **climatology** for **pre-monsoon (MAM)** and **monsoon (JJAS)** season was derived from ERA5 multiple level (1000-900hpa) temperature data (1981–2010) and computed in :\n",
    "    - `climatology_calculation_Temperature_(vertically_averaged).ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Heat date list\n",
    "list_hw=pd.read_csv('/content/drive/MyDrive/AP_HW/Scripts-ll/HW_dates/data/HW_list_rolling_def.csv')\n",
    "list_hw['Starting_Date'] = pd.to_datetime(list_hw[\"Starting_Date\"])\n",
    "list_hw['Ending_Date'] = pd.to_datetime(list_hw[\"Ending_Date\"])\n",
    "\n",
    "# separate hw for mam season\n",
    "mam_hw_list =list_hw[(list_hw['Starting_Date'].dt.month >= 3) & (list_hw['Starting_Date'].dt.month <= 5)]\n",
    "mam_hw_list.reset_index(inplace=True,drop=True)\n",
    "mam_hw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Event data for composite analysis - temperature anomaly (MAM)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# List to store temperature anomalies for each event\n",
    "anom_list = []\n",
    "\n",
    "# Loop over MAM heatwave events\n",
    "for i in tqdm(range(len(mam_hw_list['Starting_Date']))):\n",
    "    # Extract event year and dates\n",
    "    year = mam_hw_list['Starting_Date'].dt.year.iloc[i]\n",
    "    start_time = str(mam_hw_list['Starting_Date'][i])\n",
    "    end_time = str(mam_hw_list['Ending_Date'][i])\n",
    "\n",
    "    # Adjust times to Bangladesh timezone\n",
    "    start_time = str(np.datetime64(start_time) - np.timedelta64(6, 'h'))  # Subtract 6h\n",
    "    end_time = str(np.datetime64(end_time) - np.timedelta64(6, 'h') + np.timedelta64(24, 'h'))  # Include end date\n",
    "    time_range = slice(start_time, end_time)\n",
    "    event_no = i + 1\n",
    "\n",
    "    ###################################\n",
    "    ############# temperature #########\n",
    "    # Load temperature and climatology files\n",
    "    ds_temp = xr.open_dataset(f\"/content/drive/MyDrive/AP_HW/ERA5 Data/temperature_levels(1000-900)/temp(1000-900)-{year}.nc\")\n",
    "    temp_clim = xr.open_dataset('/content/drive/MyDrive/AP_HW/Scripts-ll/climatology/data/shum&temp/temp_climatology(1000-900)-mam.nc')\n",
    "\n",
    "    # Select event period and compute mean\n",
    "    ds_temp = ds_temp.sel(valid_time=time_range)\n",
    "    ds_temp = ds_temp.mean(dim='valid_time', skipna=True)\n",
    "\n",
    "    # Compute anomaly and assign event number\n",
    "    temp_anom = ds_temp - temp_clim\n",
    "    temp_anom = temp_anom.assign_coords(event_no=event_no)\n",
    "\n",
    "    # Add to anomaly list\n",
    "    anom_list.append(temp_anom)\n",
    "\n",
    "# Concatenate all event anomalies\n",
    "temp_events_anom_mam = xr.concat(anom_list, dim='event_no')\n",
    "\n",
    "# Save to NetCDF\n",
    "temp_events_anom_mam.to_netcdf('/content/drive/MyDrive/AP_HW/Scripts-ll/temp&shum/data/temp_events_anom-mam.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Heat date list\n",
    "list_hw=pd.read_csv('/content/drive/MyDrive/AP_HW/Scripts-ll/HW_dates/data/HW_list_rolling_def.csv')\n",
    "list_hw['Starting_Date'] = pd.to_datetime(list_hw[\"Starting_Date\"])\n",
    "list_hw['Ending_Date'] = pd.to_datetime(list_hw[\"Ending_Date\"])\n",
    "\n",
    "# separate hw for jjas season\n",
    "jjas_hw_list =list_hw[(list_hw['Starting_Date'].dt.month >= 6) & (list_hw['Starting_Date'].dt.month <= 9)]\n",
    "jjas_hw_list.reset_index(inplace=True,drop=True)\n",
    "jjas_hw_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Event data for composite analysis - temperature anomaly (JJAS)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# List to store temperature anomalies for each event\n",
    "anom_list = []\n",
    "\n",
    "# Loop over JJAS heatwave events\n",
    "for i in tqdm(range(len(jjas_hw_list['Starting_Date']))):\n",
    "    # Extract event year and dates\n",
    "    year = jjas_hw_list['Starting_Date'].dt.year.iloc[i]\n",
    "    start_time = str(jjas_hw_list['Starting_Date'][i])\n",
    "    end_time = str(jjas_hw_list['Ending_Date'][i])\n",
    "\n",
    "    # Adjust times to Bangladesh timezone\n",
    "    start_time = str(np.datetime64(start_time) - np.timedelta64(6, 'h'))  # Subtract 6h\n",
    "    end_time = str(np.datetime64(end_time) - np.timedelta64(6, 'h') + np.timedelta64(24, 'h'))  # Include end date\n",
    "    time_range = slice(start_time, end_time)\n",
    "    event_no = i + 1\n",
    "\n",
    "    ###################################\n",
    "    ############# temperature #########\n",
    "    # Load  temperature and climatology files\n",
    "    ds_temp = xr.open_dataset(f\"/content/drive/MyDrive/AP_HW/ERA5 Data/temperature_levels(1000-900)/temp(1000-900)-{year}.nc\")\n",
    "    temp_clim = xr.open_dataset('/content/drive/MyDrive/AP_HW/Scripts-ll/climatology/data/shum&temp/temp_climatology(1000-900)-jjas.nc')\n",
    "\n",
    "    # Select event period and compute mean\n",
    "    ds_temp = ds_temp.sel(valid_time=time_range)\n",
    "    ds_temp = ds_temp.mean(dim='valid_time', skipna=True)\n",
    "\n",
    "    # Compute anomaly and assign event number\n",
    "    temp_anom = ds_temp - temp_clim\n",
    "    temp_anom = temp_anom.assign_coords(event_no=event_no)\n",
    "\n",
    "    # Add to anomaly list\n",
    "    anom_list.append(temp_anom)\n",
    "\n",
    "# Concatenate all event anomalies\n",
    "temp_events_anom_jjas = xr.concat(anom_list, dim='event_no')\n",
    "\n",
    "# Save to NetCDF\n",
    "temp_events_anom_jjas.to_netcdf('/content/drive/MyDrive/AP_HW/Scripts-ll/temp&shum/data/temp_events_anom-jjas.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lJk_WvyuGYo"
   },
   "source": [
    "# Specific humidity Anomaly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OfyZ2GqZpl8"
   },
   "source": [
    "\n",
    "*   We calculated the **Specific humidity anomalies** for each event using the dates from `HW_list_rolling_def.csv` for **pre-monsoon (MAM)** and **monsoon (JJAS)** seasons.  \n",
    "*   The **climatology** for **pre-monsoon (MAM)** and **monsoon (JJAS)** season was derived from ERA5 multiple level (1000-900hpa) Specific humidity data (1981–2010) and computed in :\n",
    "    - `climatology_calculation_specific_humidity_(vertically_averaged).ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Heat date list\n",
    "list_hw=pd.read_csv('/content/drive/MyDrive/AP_HW/Scripts-ll/HW_dates/data/HW_list_rolling_def.csv')\n",
    "list_hw['Starting_Date'] = pd.to_datetime(list_hw[\"Starting_Date\"])\n",
    "list_hw['Ending_Date'] = pd.to_datetime(list_hw[\"Ending_Date\"])\n",
    "\n",
    "# separate hw for mam season\n",
    "mam_hw_list =list_hw[(list_hw['Starting_Date'].dt.month >= 3) & (list_hw['Starting_Date'].dt.month <= 5)]\n",
    "mam_hw_list.reset_index(inplace=True,drop=True)\n",
    "mam_hw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Event data for composite analysis - specific humidity anomaly (MAM)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# List to store specific humidity anomalies for each event\n",
    "anom_list = []\n",
    "\n",
    "# Loop over MAM heatwave events\n",
    "for i in tqdm(range(len(mam_hw_list['Starting_Date']))):\n",
    "    # Extract event year and dates\n",
    "    year = mam_hw_list['Starting_Date'].dt.year.iloc[i]\n",
    "    start_time = str(mam_hw_list['Starting_Date'][i])\n",
    "    end_time = str(mam_hw_list['Ending_Date'][i])\n",
    "\n",
    "    # Adjust times to Bangladesh timezone\n",
    "    start_time = str(np.datetime64(start_time) - np.timedelta64(6, 'h'))  # Subtract 6h\n",
    "    end_time = str(np.datetime64(end_time) - np.timedelta64(6, 'h') + np.timedelta64(24, 'h'))  # Include end date\n",
    "    time_range = slice(start_time, end_time)\n",
    "    event_no = i + 1\n",
    "\n",
    "    ###################################\n",
    "    ############# specific humidity ####\n",
    "    # Load event-specific specific humidity and climatology\n",
    "    ds_shum = xr.open_dataset(f\"/content/drive/MyDrive/AP_HW/ERA5 Data/specific_humidity/shum-{year}.nc\")\n",
    "    shum_clim = xr.open_dataset('/content/drive/MyDrive/AP_HW/Scripts-ll/climatology/data/shum&temp/shum_climatology(1000-900)-mam.nc')\n",
    "\n",
    "    # Select event period and compute mean\n",
    "    ds_shum = ds_shum.sel(valid_time=time_range)\n",
    "    ds_shum = ds_shum.mean(dim='valid_time', skipna=True)\n",
    "\n",
    "    # Compute anomaly and assign event number\n",
    "    shum_anom = ds_shum - shum_clim\n",
    "    shum_anom = shum_anom.assign_coords(event_no=event_no)\n",
    "\n",
    "    # Add to anomaly list\n",
    "    anom_list.append(shum_anom)\n",
    "\n",
    "# Concatenate all event anomalies\n",
    "shum_events_anom_mam = xr.concat(anom_list, dim='event_no')\n",
    "\n",
    "# Save to NetCDF\n",
    "shum_events_anom_mam.to_netcdf('/content/drive/MyDrive/AP_HW/Scripts-ll/temp&shum/data/shum_events_anom-mam.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Heat date list\n",
    "list_hw=pd.read_csv('/content/drive/MyDrive/AP_HW/Scripts-ll/HW_dates/data/HW_list_rolling_def.csv')\n",
    "list_hw['Starting_Date'] = pd.to_datetime(list_hw[\"Starting_Date\"])\n",
    "list_hw['Ending_Date'] = pd.to_datetime(list_hw[\"Ending_Date\"])\n",
    "\n",
    "# separate hw for jjas season\n",
    "jjas_hw_list =list_hw[(list_hw['Starting_Date'].dt.month >= 6) & (list_hw['Starting_Date'].dt.month <= 9)]\n",
    "jjas_hw_list.reset_index(inplace=True,drop=True)\n",
    "jjas_hw_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Event data for composite analysis - specific humidity anomaly (JJAS)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# List to store specific humidity anomalies for each event\n",
    "anom_list = []\n",
    "\n",
    "# Loop over JJAS heatwave events\n",
    "for i in tqdm(range(len(jjas_hw_list['Starting_Date']))):\n",
    "    # Extract event year and dates\n",
    "    year = jjas_hw_list['Starting_Date'].dt.year.iloc[i]\n",
    "    start_time = str(jjas_hw_list['Starting_Date'][i])\n",
    "    end_time = str(jjas_hw_list['Ending_Date'][i])\n",
    "\n",
    "    # Adjust times to Bangladesh timezone\n",
    "    start_time = str(np.datetime64(start_time) - np.timedelta64(6, 'h'))  # Subtract 6h\n",
    "    end_time = str(np.datetime64(end_time) - np.timedelta64(6, 'h') + np.timedelta64(24, 'h'))  # Include end date\n",
    "    time_range = slice(start_time, end_time)\n",
    "    event_no = i + 1\n",
    "\n",
    "    ###################################\n",
    "    ############# specific humidity ####\n",
    "    # Load event-specific specific humidity and climatology\n",
    "    ds_shum = xr.open_dataset(f\"/content/drive/MyDrive/AP_HW/ERA5 Data/specific_humidity/shum-{year}.nc\")\n",
    "    shum_clim = xr.open_dataset('/content/drive/MyDrive/AP_HW/Scripts-ll/climatology/data/shum&temp/shum_climatology(1000-900)-jjas.nc')\n",
    "\n",
    "    # Select event period and compute mean\n",
    "    ds_shum = ds_shum.sel(valid_time=time_range)\n",
    "    ds_shum = ds_shum.mean(dim='valid_time', skipna=True)\n",
    "\n",
    "    # Compute anomaly and assign event number\n",
    "    shum_anom = ds_shum - shum_clim\n",
    "    shum_anom = shum_anom.assign_coords(event_no=event_no)\n",
    "\n",
    "    # Add to anomaly list\n",
    "    anom_list.append(shum_anom)\n",
    "\n",
    "# Concatenate all event anomalies\n",
    "shum_events_anom_jjas = xr.concat(anom_list, dim='event_no')\n",
    "\n",
    "# Save to NetCDF\n",
    "shum_events_anom_jjas.to_netcdf('/content/drive/MyDrive/AP_HW/Scripts-ll/temp&shum/data/shum_events_anom-jjas.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xj4q-50VZAy5"
   },
   "source": [
    "# Combine Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xqaTlzQaRf4"
   },
   "source": [
    "- We have plotted anomalies of vertically averaged **temperature and specific humidity**.\n",
    "\n",
    "- Anomalies were calculated above in sections:  \n",
    "  - `Temperature Anomaly`\n",
    "`  \n",
    "  - `Specific humidity Anomaly`\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels_temp=np.arange(-5, 5+ 0.0001, 1)\n",
    "levels_shum=np.arange(-0.003, 0.003 + 0.0001, 0.0005)\n",
    "projection=ccrs.PlateCarree()\n",
    "fig,axes=plt.subplots(ncols=2,nrows=2,subplot_kw={'projection':projection},figsize=(10, 25))\n",
    "\n",
    "#  premonsoon temp\n",
    "ax=axes.flat[0]\n",
    "temp=xr.open_dataset('/content/drive/MyDrive/AP_HW/Scripts-ll/temp&shum/data/temp_events_anom-mam.nc')\n",
    "\n",
    "# Spatial region\n",
    "lat_range=slice(38,5)\n",
    "lon_range=slice(60,98)\n",
    "temp=temp.sel(latitude=lat_range,longitude=lon_range)\n",
    "temp_anom=temp.mean(dim='event_no',skipna=True)\n",
    "temp_anom=temp_anom.mean(dim='pressure_level',skipna=True)\n",
    "\n",
    "latitude=temp_anom['latitude'].values\n",
    "longitude=temp_anom['longitude'].values\n",
    "contourf_temp=ax.contourf(longitude,latitude,temp_anom.t,levels=levels_temp,cmap='seismic',extend='both',transform=projection)\n",
    "# cbar = plt.colorbar(contourf, ax=ax, orientation='horizontal', pad=0.01,fraction=0.06, label=\"${Pa}$\")\n",
    "\n",
    "ax.gridlines(draw_labels=['left','bottom'],visible=False)\n",
    "ax.coastlines()\n",
    "ax.set_title(\"(a) Temperature Anomalies - Pre-monsoon\",fontsize=10)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.add_feature(cf.BORDERS.with_scale('10m'))\n",
    "\n",
    "# premonsoon shum\n",
    "ax=axes.flat[1]\n",
    "shum=xr.open_dataset('/content/drive/MyDrive/AP_HW/Scripts-ll/temp&shum/data/shum_events_anom-mam.nc')\n",
    "\n",
    "# Spatial region\n",
    "lat_range=slice(38,5)\n",
    "lon_range=slice(60,98)\n",
    "shum=shum.sel(latitude=lat_range,longitude=lon_range)\n",
    "shum_anom=shum.mean(dim='event_no',skipna=True)\n",
    "shum_anom=shum_anom.mean(dim='pressure_level',skipna=True)\n",
    "\n",
    "latitude=shum_anom['latitude'].values\n",
    "longitude=shum_anom['longitude'].values\n",
    "contourf_shum=ax.contourf(longitude,latitude,shum_anom.q,levels=levels_shum,cmap='seismic',extend='both',transform=projection)\n",
    "# cbar = plt.colorbar(contourf, ax=ax, orientation='horizontal', pad=0.01,fraction=0.06, label=\"${Pa}$\")\n",
    "\n",
    "ax.gridlines(draw_labels=['bottom'],visible=False)\n",
    "ax.coastlines()\n",
    "ax.set_title(\"(b) Specific Humidity Anomalies - Pre-monsoon\",fontsize=10)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.add_feature(cf.BORDERS.with_scale('10m'))\n",
    "\n",
    "\n",
    "# monsoon temp\n",
    "ax=axes.flat[2]\n",
    "temp=xr.open_dataset('/content/drive/MyDrive/AP_HW/Scripts-ll/temp&shum/data/temp_events_anom-jjas.nc')\n",
    "\n",
    "# Spatial region\n",
    "lat_range=slice(38,5)\n",
    "lon_range=slice(60,98)\n",
    "temp=temp.sel(latitude=lat_range,longitude=lon_range)\n",
    "temp_anom=temp.mean(dim='event_no',skipna=True)\n",
    "temp_anom=temp_anom.mean(dim='pressure_level',skipna=True)\n",
    "\n",
    "latitude=temp_anom['latitude'].values\n",
    "longitude=temp_anom['longitude'].values\n",
    "contourf_temp=ax.contourf(longitude,latitude,temp_anom.t,levels=levels_temp,cmap='seismic',extend='both',transform=projection)\n",
    "# cbar = plt.colorbar(contourf, ax=ax, orientation='horizontal', pad=0.01,fraction=0.06, label=\"${Pa}$\")\n",
    "\n",
    "ax.gridlines(draw_labels=['left','bottom'],visible=False)\n",
    "ax.coastlines()\n",
    "ax.set_title(\"(c) Temperature Anomalies - Monsoon\",fontsize=10)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.add_feature(cf.BORDERS.with_scale('10m'))\n",
    "\n",
    "# monsoon shum\n",
    "ax=axes.flat[3]\n",
    "shum=xr.open_dataset('/content/drive/MyDrive/AP_HW/Scripts-ll/temp&shum/data/shum_events_anom-jjas.nc')\n",
    "\n",
    "# Spatial region\n",
    "lat_range=slice(38,5)\n",
    "lon_range=slice(60,98)\n",
    "shum=shum.sel(latitude=lat_range,longitude=lon_range)\n",
    "shum_anom=shum.mean(dim='event_no',skipna=True)\n",
    "shum_anom=shum_anom.mean(dim='pressure_level',skipna=True)\n",
    "\n",
    "latitude=shum_anom['latitude'].values\n",
    "longitude=shum_anom['longitude'].values\n",
    "contourf_shum=ax.contourf(longitude,latitude,shum_anom.q,levels=levels_shum,cmap='seismic',extend='both',transform=projection)\n",
    "# cbar = plt.colorbar(contourf, ax=ax, orientation='horizontal', pad=0.01,fraction=0.06, label=\"${Pa}$\")\n",
    "\n",
    "ax.gridlines(draw_labels=['bottom'],visible=False)\n",
    "ax.coastlines()\n",
    "ax.set_title(\"(d) Specific Humidity Anomalies - Monsoon\",fontsize=10)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.add_feature(cf.BORDERS.with_scale('10m'))\n",
    "\n",
    "#  contour levels for temperature\n",
    "cbar_temp = plt.colorbar(contourf_temp, ax=axes, orientation='horizontal', pad=0.01, fraction=0.01, aspect=35, label=\"${Temperature}\\ ({°C})$\")\n",
    "cbar_temp.set_ticks(levels_temp[::2])  # Set the colorbar ticks to match the levels used in contour plots\n",
    "# Adjust colorbar position\n",
    "cbar_temp.ax.set_position([0.125, 0.075, 0.38, 0.025]) # [left, bottom, width, height]\n",
    "\n",
    "#  contour levels for shum\n",
    "cbar_shum = plt.colorbar(contourf_shum, ax=axes, orientation='horizontal', pad=0.01, fraction=0.01, aspect=35, label=\"${Specific\\ Humidity}\\ ({kg}{kg}^{-1})$\")\n",
    "cbar_shum.set_ticks(levels_shum[::2])  # colorbar ticks\n",
    "# Adjust colorbar position\n",
    "cbar_shum.ax.set_position([0.525, 0.075, 0.38, 0.025]) # [left, bottom, width, height]\n",
    "\n",
    "\n",
    "plt.subplots_adjust( wspace=0.05,hspace=-0.76,top=0.9)\n",
    "plt.suptitle('Composite of 1000-900hPa Vertically Averaged Anomalies ', x=0.5, y=0.41,fontsize=11)\n",
    "plt.show()\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(\"/content/drive/MyDrive/AP_HW/Scripts-ll/Manuscript codes/All_Figures/Fig_8_anomaly_of_vertically_averaged_sh_and_temp.jpg\",\n",
    "            dpi=300, format=\"jpg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
